{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing wind interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "wind speed\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Warning - defaulting to search with facets=*\n",
      "\n",
      "This behavior is kept for backward-compatibility, but ESGF indexes might not\n",
      "successfully perform a distributed search when this option is used, so some\n",
      "results may be missing.  For full results, it is recommended to pass a list of\n",
      "facets of interest when instantiating a context object.  For example,\n",
      "\n",
      "      ctx = conn.new_context(facets='project,experiment_id')\n",
      "\n",
      "Only the facets that you specify will be present in the facets_counts dictionary.\n",
      "\n",
      "This warning is displayed when a distributed search is performed while using the\n",
      "facets=* default, a maximum of once per context object.  To suppress this warning,\n",
      "set the environment variable ESGF_PYCLIENT_NO_FACETS_STAR_WARNING to any value\n",
      "or explicitly use  conn.new_context(facets='*')\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Warning - defaulting to search with facets=*\n",
      "\n",
      "This behavior is kept for backward-compatibility, but ESGF indexes might not\n",
      "successfully perform a distributed search when this option is used, so some\n",
      "results may be missing.  For full results, it is recommended to pass a list of\n",
      "facets of interest when instantiating a context object.  For example,\n",
      "\n",
      "      ctx = conn.new_context(facets='project,experiment_id')\n",
      "\n",
      "Only the facets that you specify will be present in the facets_counts dictionary.\n",
      "\n",
      "This warning is displayed when a distributed search is performed while using the\n",
      "facets=* default, a maximum of once per context object.  To suppress this warning,\n",
      "set the environment variable ESGF_PYCLIENT_NO_FACETS_STAR_WARNING to any value\n",
      "or explicitly use  conn.new_context(facets='*')\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Warning - defaulting to search with facets=*\n",
      "\n",
      "This behavior is kept for backward-compatibility, but ESGF indexes might not\n",
      "successfully perform a distributed search when this option is used, so some\n",
      "results may be missing.  For full results, it is recommended to pass a list of\n",
      "facets of interest when instantiating a context object.  For example,\n",
      "\n",
      "      ctx = conn.new_context(facets='project,experiment_id')\n",
      "\n",
      "Only the facets that you specify will be present in the facets_counts dictionary.\n",
      "\n",
      "This warning is displayed when a distributed search is performed while using the\n",
      "facets=* default, a maximum of once per context object.  To suppress this warning,\n",
      "set the environment variable ESGF_PYCLIENT_NO_FACETS_STAR_WARNING to any value\n",
      "or explicitly use  conn.new_context(facets='*')\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Warning - defaulting to search with facets=*\n",
      "\n",
      "This behavior is kept for backward-compatibility, but ESGF indexes might not\n",
      "successfully perform a distributed search when this option is used, so some\n",
      "results may be missing.  For full results, it is recommended to pass a list of\n",
      "facets of interest when instantiating a context object.  For example,\n",
      "\n",
      "      ctx = conn.new_context(facets='project,experiment_id')\n",
      "\n",
      "Only the facets that you specify will be present in the facets_counts dictionary.\n",
      "\n",
      "This warning is displayed when a distributed search is performed while using the\n",
      "facets=* default, a maximum of once per context object.  To suppress this warning,\n",
      "set the environment variable ESGF_PYCLIENT_NO_FACETS_STAR_WARNING to any value\n",
      "or explicitly use  conn.new_context(facets='*')\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Warning - defaulting to search with facets=*\n",
      "\n",
      "This behavior is kept for backward-compatibility, but ESGF indexes might not\n",
      "successfully perform a distributed search when this option is used, so some\n",
      "results may be missing.  For full results, it is recommended to pass a list of\n",
      "facets of interest when instantiating a context object.  For example,\n",
      "\n",
      "      ctx = conn.new_context(facets='project,experiment_id')\n",
      "\n",
      "Only the facets that you specify will be present in the facets_counts dictionary.\n",
      "\n",
      "This warning is displayed when a distributed search is performed while using the\n",
      "facets=* default, a maximum of once per context object.  To suppress this warning,\n",
      "set the environment variable ESGF_PYCLIENT_NO_FACETS_STAR_WARNING to any value\n",
      "or explicitly use  conn.new_context(facets='*')\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Warning - defaulting to search with facets=*\n",
      "\n",
      "This behavior is kept for backward-compatibility, but ESGF indexes might not\n",
      "successfully perform a distributed search when this option is used, so some\n",
      "results may be missing.  For full results, it is recommended to pass a list of\n",
      "facets of interest when instantiating a context object.  For example,\n",
      "\n",
      "      ctx = conn.new_context(facets='project,experiment_id')\n",
      "\n",
      "Only the facets that you specify will be present in the facets_counts dictionary.\n",
      "\n",
      "This warning is displayed when a distributed search is performed while using the\n",
      "facets=* default, a maximum of once per context object.  To suppress this warning,\n",
      "set the environment variable ESGF_PYCLIENT_NO_FACETS_STAR_WARNING to any value\n",
      "or explicitly use  conn.new_context(facets='*')\n",
      "\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind speed ends\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"not all values found in index 'time'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 61\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m# read cmip files\u001b[39;00m\n\u001b[1;32m     54\u001b[0m cutout_cmip \u001b[39m=\u001b[39m atlite\u001b[39m.\u001b[39mCutout(path\u001b[39m=\u001b[39mfilename,\n\u001b[1;32m     55\u001b[0m                             module\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcmip\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[1;32m     56\u001b[0m                             x\u001b[39m=\u001b[39m\u001b[39mslice\u001b[39m(x1,x2), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m                             esgf_params\u001b[39m=\u001b[39mesgf_params, \n\u001b[1;32m     60\u001b[0m                             dt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m6H\u001b[39m\u001b[39m'\u001b[39m, dx\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,dy\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m cutout_cmip\u001b[39m.\u001b[39;49mprepare()\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/atlite/data.py:102\u001b[0m, in \u001b[0;36mmaybe_remove_tmpdir.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtmpdir\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m mkdtemp()\n\u001b[1;32m    101\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    103\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     rmtree(kwargs[\u001b[39m\"\u001b[39m\u001b[39mtmpdir\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/atlite/data.py:164\u001b[0m, in \u001b[0;36mcutout_prepare\u001b[0;34m(cutout, features, tmpdir, overwrite)\u001b[0m\n\u001b[1;32m    162\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCalculating and writing with module \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m missing_features \u001b[39m=\u001b[39m missing_vars\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39munique(\u001b[39m\"\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m ds \u001b[39m=\u001b[39m get_features(cutout, module, missing_features, tmpdir\u001b[39m=\u001b[39;49mtmpdir)\n\u001b[1;32m    165\u001b[0m prepared \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(missing_features)\n\u001b[1;32m    167\u001b[0m cutout\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(prepared_features\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(prepared)))\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/atlite/data.py:46\u001b[0m, in \u001b[0;36mget_features\u001b[0;34m(cutout, module, features, tmpdir)\u001b[0m\n\u001b[1;32m     41\u001b[0m     feature_data \u001b[39m=\u001b[39m delayed(get_data)(\n\u001b[1;32m     42\u001b[0m         cutout, feature, tmpdir\u001b[39m=\u001b[39mtmpdir, lock\u001b[39m=\u001b[39mlock, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameters\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     datasets\u001b[39m.\u001b[39mappend(feature_data)\n\u001b[0;32m---> 46\u001b[0m datasets \u001b[39m=\u001b[39m compute(\u001b[39m*\u001b[39;49mdatasets)\n\u001b[1;32m     48\u001b[0m ds \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mmerge(datasets, compat\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mequals\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m ds:\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/dask/base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[1;32m    598\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 600\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    601\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     90\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[1;32m     91\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[1;32m     92\u001b[0m     dsk,\n\u001b[1;32m     93\u001b[0m     keys,\n\u001b[1;32m     94\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[1;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[1;32m     97\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[39m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[39m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m][key] \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[39m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, data)\n\u001b[1;32m    225\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[39m=\u001b[39m dumps((result, \u001b[39mid\u001b[39m))\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/dask/utils.py:71\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, args, kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m\"\"\"Apply a function given its positional and keyword arguments.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[39mEquivalent to ``func(*args, **kwargs)``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m>>> dsk = {'task-name': task}  # adds the task to a low level Dask task graph\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/atlite/datasets/cmip.py:305\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(cutout, feature, tmpdir, lock, **creation_parameters)\u001b[0m\n\u001b[1;32m    302\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRequesting data for feature \u001b[39m\u001b[39m{\u001b[39;00mfeature\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    304\u001b[0m ds \u001b[39m=\u001b[39m func(esgf_params, cutout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mretrieval_params)\n\u001b[0;32m--> 305\u001b[0m ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39;49msel(time\u001b[39m=\u001b[39;49mcoords[\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    306\u001b[0m bounds \u001b[39m=\u001b[39m cutout\u001b[39m.\u001b[39mbounds\n\u001b[1;32m    307\u001b[0m ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39msel(x\u001b[39m=\u001b[39m\u001b[39mslice\u001b[39m(bounds[\u001b[39m0\u001b[39m], bounds[\u001b[39m2\u001b[39m]), y\u001b[39m=\u001b[39m\u001b[39mslice\u001b[39m(bounds[\u001b[39m1\u001b[39m], bounds[\u001b[39m3\u001b[39m]))\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/xarray/core/dataset.py:2565\u001b[0m, in \u001b[0;36mDataset.sel\u001b[0;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   2504\u001b[0m \u001b[39m\"\"\"Returns a new dataset with each array indexed by tick labels\u001b[39;00m\n\u001b[1;32m   2505\u001b[0m \u001b[39malong the specified dimension(s).\u001b[39;00m\n\u001b[1;32m   2506\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[39mDataArray.sel\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m indexers \u001b[39m=\u001b[39m either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[39m\"\u001b[39m\u001b[39msel\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2565\u001b[0m query_results \u001b[39m=\u001b[39m map_index_queries(\n\u001b[1;32m   2566\u001b[0m     \u001b[39mself\u001b[39;49m, indexers\u001b[39m=\u001b[39;49mindexers, method\u001b[39m=\u001b[39;49mmethod, tolerance\u001b[39m=\u001b[39;49mtolerance\n\u001b[1;32m   2567\u001b[0m )\n\u001b[1;32m   2569\u001b[0m \u001b[39mif\u001b[39;00m drop:\n\u001b[1;32m   2570\u001b[0m     no_scalar_variables \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/xarray/core/indexing.py:183\u001b[0m, in \u001b[0;36mmap_index_queries\u001b[0;34m(obj, indexers, method, tolerance, **indexers_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         results\u001b[39m.\u001b[39mappend(IndexSelResult(labels))\n\u001b[1;32m    182\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m         results\u001b[39m.\u001b[39mappend(index\u001b[39m.\u001b[39;49msel(labels, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions))\n\u001b[1;32m    185\u001b[0m merged \u001b[39m=\u001b[39m merge_sel_results(results)\n\u001b[1;32m    187\u001b[0m \u001b[39m# drop dimension coordinates found in dimension indexers\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m# (also drop multi-index if any)\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m# (.sel() already ensures alignment)\u001b[39;00m\n",
      "File \u001b[0;32m/media/guillerv/Windows/environments/CMIP6/lib/python3.10/site-packages/xarray/core/indexes.py:485\u001b[0m, in \u001b[0;36mPandasIndex.sel\u001b[0;34m(self, labels, method, tolerance)\u001b[0m\n\u001b[1;32m    483\u001b[0m     indexer \u001b[39m=\u001b[39m get_indexer_nd(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, label_array, method, tolerance)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(indexer \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m--> 485\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnot all values found in index \u001b[39m\u001b[39m{\u001b[39;00mcoord_name\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    487\u001b[0m \u001b[39m# attach dimension names and/or coordinates to positional indexer\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(label, Variable):\n",
      "\u001b[0;31mKeyError\u001b[0m: \"not all values found in index 'time'\""
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import atlite\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from pyesgf.logon import LogonManager\n",
    "\n",
    "lm = LogonManager()\n",
    "lm.logoff()\n",
    "lm.is_logged_on()\n",
    "\n",
    "USERNAME='guillerv'\n",
    "OPENID = f'https://esgf-data.dkrz.de/esgf-idp/openid/guillerv'\n",
    "lm.logon_with_openid(openid=OPENID, password=None, bootstrap=True)\n",
    "lm.is_logged_on()\n",
    "\n",
    "# set lat and lon\n",
    "x1 = -30\n",
    "y1 = 20\n",
    "x2 = 50\n",
    "y2 = 75\n",
    "\n",
    "# configuration parameter\n",
    "\n",
    "exp_id = \"ssp585\"\n",
    "\n",
    "esgf_params = {\n",
    "   #'data_node': 'esgf.ceda.ac.uk',\n",
    "   'source_id': 'MPI-ESM1-2-LR',\n",
    "   'variant_label':'r29i1p1f1',\n",
    "   'experiment_id': exp_id,\n",
    "   'project' : 'CMIP6'}\n",
    "\n",
    "\n",
    "# exp_id = \"ssp585\"\n",
    "\n",
    "# esgf_params = {\n",
    "#    #'data_node': 'esgf.ceda.ac.uk',\n",
    "#    'source_id': 'AWI-CM-1-1-MR',\n",
    "#    'variant_label':'r1i1p1f1',\n",
    "#    'experiment_id': exp_id,\n",
    "#    'project' : 'CMIP6'}\n",
    "\n",
    "# years for cmip6\n",
    "cmipyears = range(2015,2016)\n",
    "\n",
    "\n",
    "for year in cmipyears:\n",
    "    print(year)\n",
    "    filename = \"./data/test_wind/cmip2_\"+str(year)+\".nc\"\n",
    "    # read cmip files\n",
    "    cutout_cmip = atlite.Cutout(path=filename,\n",
    "                                module=[\"cmip\"], \n",
    "                                x=slice(x1,x2), \n",
    "                                y=slice(y1,y2), \n",
    "                                time=str(year), \n",
    "                                esgf_params=esgf_params, \n",
    "                                dt='6H', dx=1,dy=1)\n",
    "    cutout_cmip.prepare()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2279407f323531b0c201f0ec23554de97ccb9ca125c8b01aed665416b56517d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
